{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install opencv-python pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Azure AI Services**\n",
    "\n",
    "Login to Azure using the Azure portal and retrieve your service endpoint and key.\n",
    "\n",
    "- Open Microsoft Edge using the desktop shortcut and open Azure portal using the bookmark.\n",
    "\n",
    "- Login using the Azure credentials in the Resources tab of the lab guide.\n",
    "\n",
    "- Inside Azure portal, search for Azure AI Services and select it.\n",
    "\n",
    "    ![A screenshot showing Azure AI services being searched for in the dropdown](../labguide/img/azureportal_ai_search.png)\n",
    "\n",
    "- Note the name of the Azure AI service that was precreated for you and then click on the resource.\n",
    "\n",
    "    ![A screenshot showing an Azure AI service inside a resource group in Azure portal](../labguide/img/azure_ai_service.png)\n",
    "\n",
    "- You will need the AI service name, language endpoint and one of the key values for the Azure AI Service. You will need these values in the next cell. Review the screenshot and locate these values in your Azure environment, then replace the placeholders in the next cell with your values.\n",
    "\n",
    "    1. Service name\n",
    "    2. Key (pick either key 1 or key 2)\n",
    "    3. Language endpoint\n",
    "\n",
    "    ![A screenshot showing an Azure AI service overview page in Azure portal](../labguide/img/ai_endpoint_key.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions\n",
    "\n",
    "We will define two functions to assist with invoking the gpt-4o model's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, base64\n",
    "from pprint import pprint\n",
    "\n",
    "# Call the AI service API\n",
    "def call_api(uri, key, payload):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": key,\n",
    "    }\n",
    "    # Send request\n",
    "    try:\n",
    "        response = requests.post(uri, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "    # Handle the response as needed (e.g., print or process)\n",
    "    response_json = response.json()\n",
    "    return response_json\n",
    "\n",
    "# Convert an image to base64 encoding\n",
    "def image_to_base64(image_path_or_url):\n",
    "    if image_path_or_url.startswith('http://') or image_path_or_url.startswith('https://'):\n",
    "        response = requests.get(image_path_or_url)\n",
    "        image_data = response.content\n",
    "    else:\n",
    "        with open(image_path_or_url, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "    return base64.b64encode(image_data).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure with your Azure AI service endpoint and key\n",
    "\n",
    "Replace the placeholders in the code block below endpoint and key you retrieved.\n",
    "\n",
    "1. *azureAiServiceName*\n",
    "2. *API_KEY*\n",
    "3. *serviceUri*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these values with the correct values from your Azure AI service\n",
    "azureAiServiceName = \"replace_me_with_your_service\" # 1 - Service name\n",
    "API_KEY = \"replace_me_with_your_key\" # 2 - API Key\n",
    "serviceUri = \"replace_me_with_your_service_endpoint\" # 3 - service endpoint\n",
    "\n",
    "IMAGE_PATH=\"../media/image/people_on_street.jpg\" # 4 - Image path\n",
    "ENDPOINT = f\"{serviceUri}openai/deployments/{azureAiServiceName}-gpt-4o-mini-deployment/chat/completions?api-version=2024-08-01-preview\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with a prompt\n",
    "\n",
    "Now we can initialize gpt-4o with a prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payload for the request\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "call_api(ENDPOINT, API_KEY, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe an image with a prompt\n",
    "\n",
    "To send an image with our prompt we will convert it to base64 and include it in the payload of our API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace IMAGE_PATH with the path to the image you want to describe, or use the provided sample image.\n",
    "IMAGE_PATH = \"../media/image/columns.png\"\n",
    "image_base64 = image_to_base64(IMAGE_PATH)\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" }, # provide context for the model to generate a response\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\"  # tell the model what to do\n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"data:image/png;base64,\" + image_base64 # send the base64 encoded image with the payload\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "pprint(call_api(ENDPOINT, API_KEY, payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other images. \n",
    "\n",
    "You can use any public URI as the IMAGE_PATH. Try uncommenting the samples below to try out different images and settings. \n",
    "\n",
    "You can also change the \"role\" prompt to get gpt-4o to respond more specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace IMAGE_PATH with the path to the image you want to describe, or use the provided sample image.\n",
    "IMAGE_PATH = \"https://c7.alamy.com/comp/2RFM9CB/closeup-of-acrylonitrile-butadiene-gloves-production-line-2RFM9CB.jpg\"\n",
    "#IMAGE_PATH = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS3SyqcyXM0W3Sx3Q0DKPVkBu9GlxN7b06TQg&s\"\n",
    "image_base64 = image_to_base64(IMAGE_PATH)\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" }, # provide context for the model to generate a response\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\"  # tell the model what to do\n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"data:image/png;base64,\" + image_base64 # send the base64 encoded image with the payload\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "pprint(call_api(ENDPOINT, API_KEY, payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Lab\n",
    "Run the following cell to complete this lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r userId\n",
    "import requests;print(requests.post(\"https://jsleaderboard001-cnece0effvapgbft.westus2-01.azurewebsites.net/complete_task\", headers={\"Content-Type\": \"application/json\"}, json={\"user_id\": userId, \"task_id\": 5}).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue\n",
    "\n",
    "[Notebook 6 - Camera](./6-Camera.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
